<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>memory_vibe</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><p>Okay, I have read the “vibe” description for <code>crawl4ai</code>. Based on this, and adhering to the “memory” document type requirements, here is the detailed Markdown outline:</p>
<pre class=" language-markdown"><code class="prism  language-markdown"><span class="token title important"><span class="token punctuation">#</span> Detailed Outline for crawl4ai - vibe Component</span>

<span class="token bold"><span class="token punctuation">**</span>Target Document Type:<span class="token punctuation">**</span></span> memory
<span class="token bold"><span class="token punctuation">**</span>Target Output Filename Suggestion:<span class="token punctuation">**</span></span> <span class="token code keyword" spellcheck="false">`llm_memory_vibe_coding.md`</span>
<span class="token bold"><span class="token punctuation">**</span>Library Version Context:<span class="token punctuation">**</span></span> 0.6.3
**<span class="token title important">Outline Generation Date:** 2025-05-24
<span class="token punctuation">---</span></span>

<span class="token title important"><span class="token punctuation">##</span> 1. Vibe Coding with Crawl4AI: Core Concept</span>

<span class="token list punctuation">*</span>   1.1. Purpose:
<span class="token code keyword" spellcheck="false">    *   Provides a conceptual framework for interacting with the `crawl4ai` library, particularly when using AI coding assistants.</span>
<span class="token code keyword" spellcheck="false">    *   Aims to simplify the process of building web data applications by focusing on high-level capabilities and key building blocks, enabling users to guide AI assistants effectively even with limited direct `crawl4ai` API knowledge.</span>
<span class="token list punctuation">*</span>   1.2. Principle:
<span class="token code keyword" spellcheck="false">    *   Describes how users can communicate their web scraping and data extraction goals to an AI assistant, which then translates these "vibes" or high-level intentions into `crawl4ai` Python code by leveraging knowledge of the library's core components and configurations.</span>

<span class="token title important"><span class="token punctuation">##</span> 2. </span><span class="token code keyword" spellcheck="false">`crawl4ai`</span> High-Level Capabilities (for Vibe Prompts)

<span class="token list punctuation">*</span>   2.1. Fetching Webpages
<span class="token code keyword" spellcheck="false">    *   2.1.1. Description: The library can retrieve content from specified web URLs.</span>
<span class="token list punctuation">*</span>   2.2. Converting Web Content to Clean Markdown
<span class="token code keyword" spellcheck="false">    *   2.2.1. Description: The library can process raw HTML content and convert it into a cleaned, structured Markdown format.</span>
<span class="token code keyword" spellcheck="false">    *   2.2.2. Applications: Suitable for content summarization, input for Question &amp; Answering systems, and as a pre-processing step for other LLMs.</span>
<span class="token list punctuation">*</span>   2.3. Extracting Specific Information (JSON)
<span class="token code keyword" spellcheck="false">    *   2.3.1. Description: The library can extract targeted data elements from webpages and organize them into a JSON structure.</span>
<span class="token code keyword" spellcheck="false">    *   2.3.2. Examples: Can be used to extract product names, prices from e-commerce sites, article headlines, author names, etc.</span>
<span class="token list punctuation">*</span>   2.4. Crawling Multiple Pages
<span class="token code keyword" spellcheck="false">    *   2.4.1. Description: The library supports concurrent fetching and processing of a list of URLs.</span>
<span class="token list punctuation">*</span>   2.5. Taking Screenshots and Generating PDFs
<span class="token code keyword" spellcheck="false">    *   2.5.1. Description: The library can capture visual representations of webpages as PNG screenshots or generate PDF documents.</span>
<span class="token list punctuation">*</span>   2.6. Handling Simple Page Interactions
<span class="token code keyword" spellcheck="false">    *   2.6.1. Description: The library can execute JavaScript to simulate basic user interactions on a webpage, such as clicking buttons (e.g., "load more") or scrolling.</span>

<span class="token title important"><span class="token punctuation">##</span> 3. Key </span><span class="token code keyword" spellcheck="false">`crawl4ai`</span> Building Blocks (API Reference for Vibe Coding Context)

<span class="token list punctuation">*</span>   3.1. Class <span class="token code keyword" spellcheck="false">`AsyncWebCrawler`</span>
<span class="token code keyword" spellcheck="false">    *   3.1.1. Purpose: The primary entry point and main tool within `crawl4ai` for orchestrating web crawling and data extraction tasks.</span>
<span class="token code keyword" spellcheck="false">    *   3.1.2. Initialization (`__init__`):</span>
<span class="token code keyword" spellcheck="false">        *   Signature: `AsyncWebCrawler(self, crawler_strategy: Optional[AsyncCrawlerStrategy] = None, config: Optional[BrowserConfig] = None, base_directory: str = ..., thread_safe: bool = False, logger: Optional[AsyncLoggerBase] = None, **kwargs)`</span>
<span class="token code keyword" spellcheck="false">        *   Parameters:</span>
<span class="token code keyword" spellcheck="false">            *   `crawler_strategy (Optional[AsyncCrawlerStrategy])`: The underlying strategy for web crawling (e.g., `AsyncPlaywrightCrawlerStrategy`). Defaults to `AsyncPlaywrightCrawlerStrategy`.</span>
<span class="token code keyword" spellcheck="false">            *   `config (Optional[BrowserConfig])`: Configuration for the browser instance. See section 3.5 for details.</span>
<span class="token code keyword" spellcheck="false">            *   Other parameters are generally handled by defaults for vibe coding.</span>
<span class="token list punctuation">*</span>   3.2. Method <span class="token code keyword" spellcheck="false">`AsyncWebCrawler.arun()`</span>
<span class="token code keyword" spellcheck="false">    *   3.2.1. Purpose: Executes a crawl operation on a single URL or resource.</span>
<span class="token code keyword" spellcheck="false">    *   3.2.2. Signature: `async def arun(self, url: str, config: Optional[CrawlerRunConfig] = None, **kwargs) -&gt; RunManyReturn`</span>
<span class="token code keyword" spellcheck="false">    *   3.2.3. Parameters:</span>
<span class="token code keyword" spellcheck="false">        *   `url (str)`: The target resource.</span>
<span class="token code keyword" spellcheck="false">            *   Description: Can be a standard web URL (e.g., "https://example.com"), a local file path (e.g., "file:///path/to/file.html"), or raw HTML content (e.g., "raw:&lt;html&gt;...&lt;/html&gt;").</span>
<span class="token code keyword" spellcheck="false">        *   `config (Optional[CrawlerRunConfig])`: An instance of `CrawlerRunConfig` specifying how this particular crawl run should be executed. See section 3.4 for details.</span>
<span class="token list punctuation">*</span>   3.3. Method <span class="token code keyword" spellcheck="false">`AsyncWebCrawler.arun_many()`</span>
<span class="token code keyword" spellcheck="false">    *   3.3.1. Purpose: Executes crawl operations on a list of URLs or resources, often concurrently.</span>
<span class="token code keyword" spellcheck="false">    *   3.3.2. Signature: `async def arun_many(self, urls: List[str], config: Optional[CrawlerRunConfig] = None, dispatcher: Optional[BaseDispatcher] = None, **kwargs) -&gt; RunManyReturn`</span>
<span class="token code keyword" spellcheck="false">    *   3.3.3. Parameters:</span>
<span class="token code keyword" spellcheck="false">        *   `urls (List[str])`: A list of target resources (URLs, file paths, raw HTML strings).</span>
<span class="token code keyword" spellcheck="false">        *   `config (Optional[CrawlerRunConfig])`: An instance of `CrawlerRunConfig` applied to all URLs in the list. See section 3.4 for details.</span>
<span class="token list punctuation">*</span>   3.4. Class <span class="token code keyword" spellcheck="false">`CrawlerRunConfig`</span>
<span class="token code keyword" spellcheck="false">    *   3.4.1. Purpose: Configuration object for individual crawl runs, controlling aspects like content extraction, page interaction, and output formats.</span>
<span class="token code keyword" spellcheck="false">    *   3.4.2. Key Parameters for Vibe Coding Context:</span>
<span class="token code keyword" spellcheck="false">        *   `markdown_generator (Optional[MarkdownGenerationStrategy])`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: Specifies the strategy for generating Markdown.</span>
<span class="token code keyword" spellcheck="false">            *   Default: An instance of `DefaultMarkdownGenerator`.</span>
<span class="token code keyword" spellcheck="false">            *   Note for Vibe Coding: Can be `DefaultMarkdownGenerator(content_filter=PruningContentFilter())` for cleaner output.</span>
<span class="token code keyword" spellcheck="false">        *   `extraction_strategy (Optional[ExtractionStrategy])`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: Specifies the strategy for extracting structured data.</span>
<span class="token code keyword" spellcheck="false">            *   Supported Strategies (for Vibe Coding):</span>
<span class="token code keyword" spellcheck="false">                *   `JsonCssExtractionStrategy`: For extracting data based on CSS selectors from structured HTML. Requires a `schema` dictionary.</span>
<span class="token code keyword" spellcheck="false">                *   `LLMExtractionStrategy`: For extracting data using an LLM, often for complex or unstructured HTML. Requires an `LLMConfig` and an `instruction` or Pydantic model defining the desired output.</span>
<span class="token code keyword" spellcheck="false">        *   `js_code (Optional[Union[str, List[str]]])`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: JavaScript code (or a list of code snippets) to be executed on the page after it loads.</span>
<span class="token code keyword" spellcheck="false">        *   `wait_for (Optional[str])`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: A CSS selector or JavaScript expression. The crawler will wait for this condition to be met after `js_code` execution before proceeding.</span>
<span class="token code keyword" spellcheck="false">        *   `session_id (Optional[str])`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: An identifier used to maintain the state of a browser page across multiple `arun` calls. Essential for multi-step interactions on the same page.</span>
<span class="token code keyword" spellcheck="false">        *   `js_only (bool)`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: If `True` (and `session_id` is used), only executes `js_code` on the existing page without a full navigation/reload. Default is `False`.</span>
<span class="token code keyword" spellcheck="false">        *   `screenshot (bool)`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: If `True`, captures a screenshot of the page. Result in `CrawlResult.screenshot`. Default is `False`.</span>
<span class="token code keyword" spellcheck="false">        *   `pdf (bool)`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: If `True`, generates a PDF of the page. Result in `CrawlResult.pdf`. Default is `False`.</span>
<span class="token code keyword" spellcheck="false">        *   `cache_mode (Optional[CacheMode])`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: Controls caching behavior.</span>
<span class="token code keyword" spellcheck="false">            *   Type: `crawl4ai.cache_context.CacheMode` (Enum).</span>
<span class="token code keyword" spellcheck="false">            *   Common Values: `CacheMode.ENABLED`, `CacheMode.BYPASS`.</span>
<span class="token list punctuation">*</span>   3.5. Class <span class="token code keyword" spellcheck="false">`BrowserConfig`</span>
<span class="token code keyword" spellcheck="false">    *   3.5.1. Purpose: Configures persistent browser-level settings for an `AsyncWebCrawler` instance.</span>
<span class="token code keyword" spellcheck="false">    *   3.5.2. Key Parameters for Vibe Coding Context:</span>
<span class="token code keyword" spellcheck="false">        *   `headless (bool)`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: If `True`, the browser runs without a visible UI. If `False`, the browser UI is shown.</span>
<span class="token code keyword" spellcheck="false">            *   Default: `True`.</span>
<span class="token code keyword" spellcheck="false">        *   `proxy_config (Optional[Union[ProxyConfig, Dict[str, str]]])`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: Configuration for using a proxy server.</span>
<span class="token code keyword" spellcheck="false">            *   Structure (if dict): `{"server": "http://&lt;host&gt;:&lt;port&gt;", "username": "&lt;user&gt;", "password": "&lt;pass&gt;"}`.</span>
<span class="token code keyword" spellcheck="false">        *   `user_agent (Optional[str])`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: Custom User-Agent string to be used by the browser.</span>
<span class="token list punctuation">*</span>   3.6. Class <span class="token code keyword" spellcheck="false">`LLMConfig`</span>
<span class="token code keyword" spellcheck="false">    *   3.6.1. Purpose: Configures settings for interacting with Large Language Models, used by `LLMExtractionStrategy`.</span>
<span class="token code keyword" spellcheck="false">    *   3.6.2. Key Parameters:</span>
<span class="token code keyword" spellcheck="false">        *   `provider (str)`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: Specifies the LLM provider and model identifier.</span>
<span class="token code keyword" spellcheck="false">            *   Examples: "openai/gpt-4o-mini", "ollama/llama3", "anthropic/claude-3-opus-20240229".</span>
<span class="token code keyword" spellcheck="false">        *   `api_token (Optional[str])`:</span>
<span class="token code keyword" spellcheck="false">            *   Description: API key for the LLM provider. Can be the actual key or an environment variable reference (e.g., "env:OPENAI_API_KEY").</span>
<span class="token list punctuation">*</span>   3.7. Class <span class="token code keyword" spellcheck="false">`CrawlResult`</span>
<span class="token code keyword" spellcheck="false">    *   3.7.1. Purpose: The data object returned by `crawl4ai` operations, containing the results and metadata of a crawl.</span>
<span class="token code keyword" spellcheck="false">    *   3.7.2. Key Attributes:</span>
<span class="token code keyword" spellcheck="false">        *   `success (bool)`: `True` if the crawl was successful, `False` otherwise.</span>
<span class="token code keyword" spellcheck="false">        *   `markdown (MarkdownGenerationResult)`: Object containing Markdown representations.</span>
<span class="token code keyword" spellcheck="false">            *   `markdown.raw_markdown (str)`: Markdown generated directly from the cleaned HTML.</span>
<span class="token code keyword" spellcheck="false">            *   `markdown.fit_markdown (str)`: Markdown potentially further processed by content filters.</span>
<span class="token code keyword" spellcheck="false">        *   `extracted_content (Optional[str])`: JSON string of structured data if an `ExtractionStrategy` was used and successful.</span>
<span class="token code keyword" spellcheck="false">        *   `links (Links)`: Object containing `internal` and `external` lists of `Link` objects. Each `Link` object has `href`, `text`, `title`.</span>
<span class="token code keyword" spellcheck="false">        *   `media (Media)`: Object containing lists of `MediaItem` for `images`, `videos`, `audios`, and `tables`. Each `MediaItem` has `src`, `alt`, `score`, etc.</span>
<span class="token code keyword" spellcheck="false">        *   `screenshot (Optional[str])`: Base64 encoded string of the PNG screenshot, if `screenshot=True`.</span>
<span class="token code keyword" spellcheck="false">        *   `pdf (Optional[bytes])`: Raw bytes of the PDF document, if `pdf=True`.</span>
<span class="token code keyword" spellcheck="false">        *   `error_message (Optional[str])`: Description of the error if `success` is `False`.</span>

<span class="token title important"><span class="token punctuation">##</span> 4. Common </span><span class="token code keyword" spellcheck="false">`crawl4ai`</span> Usage Patterns (Vibe Recipes Mapped to Components)

<span class="token list punctuation">*</span>   4.1. Task: Get Clean Markdown from a Page
<span class="token code keyword" spellcheck="false">    *   4.1.1. Description: Fetch a single webpage and convert its main content into clean Markdown.</span>
<span class="token code keyword" spellcheck="false">    *   4.1.2. Key `crawl4ai` elements:</span>
<span class="token code keyword" spellcheck="false">        *   `AsyncWebCrawler`</span>
<span class="token code keyword" spellcheck="false">        *   `arun()` method.</span>
<span class="token code keyword" spellcheck="false">        *   `CrawlerRunConfig`:</span>
<span class="token code keyword" spellcheck="false">            *   `markdown_generator`: Typically `DefaultMarkdownGenerator()`. For very clean output, `DefaultMarkdownGenerator(content_filter=PruningContentFilter())`.</span>
<span class="token list punctuation">*</span>   4.2. Task: Extract All Product Names and Prices from an E-commerce Category Page
<span class="token code keyword" spellcheck="false">    *   4.2.1. Description: Scrape structured data (e.g., product names, prices) from a page with repeating elements.</span>
<span class="token code keyword" spellcheck="false">    *   4.2.2. Key `crawl4ai` elements:</span>
<span class="token code keyword" spellcheck="false">        *   `AsyncWebCrawler`</span>
<span class="token code keyword" spellcheck="false">        *   `arun()` method.</span>
<span class="token code keyword" spellcheck="false">        *   `CrawlerRunConfig`:</span>
<span class="token code keyword" spellcheck="false">            *   `extraction_strategy`: `JsonCssExtractionStrategy(schema={"name_field": "h2.product-title", "price_field": "span.price"})`. The schema's CSS selectors identify where to find the data.</span>
<span class="token list punctuation">*</span>   4.3. Task: Extract Key Information from an Article using an LLM
<span class="token code keyword" spellcheck="false">    *   4.3.1. Description: Use an LLM to parse an article and extract specific fields like author, date, and a summary into a JSON format.</span>
<span class="token code keyword" spellcheck="false">    *   4.3.2. Key `crawl4ai` elements:</span>
<span class="token code keyword" spellcheck="false">        *   `AsyncWebCrawler`</span>
<span class="token code keyword" spellcheck="false">        *   `arun()` method.</span>
<span class="token code keyword" spellcheck="false">        *   `CrawlerRunConfig`:</span>
<span class="token code keyword" spellcheck="false">            *   `extraction_strategy`: `LLMExtractionStrategy(llm_config=..., instruction=..., schema=...)`.</span>
<span class="token code keyword" spellcheck="false">        *   `LLMConfig`: Instance specifying `provider` (e.g., "openai/gpt-4o-mini") and `api_token`.</span>
<span class="token code keyword" spellcheck="false">        *   Schema for `LLMExtractionStrategy`: Can be a Pydantic model definition or a dictionary describing the target JSON structure.</span>
<span class="token list punctuation">*</span>   4.4. Task: Crawl Multiple Pages of a Blog (Clicking "Next Page")
<span class="token code keyword" spellcheck="false">    *   4.4.1. Description: Navigate through paginated content by simulating clicks on "Next Page" or similar links, collecting data from each page.</span>
<span class="token code keyword" spellcheck="false">    *   4.4.2. Key `crawl4ai` elements:</span>
<span class="token code keyword" spellcheck="false">        *   `AsyncWebCrawler`</span>
<span class="token code keyword" spellcheck="false">        *   Multiple sequential calls to `arun()` (typically in a loop).</span>
<span class="token code keyword" spellcheck="false">        *   `CrawlerRunConfig` (reused or cloned for each step):</span>
<span class="token code keyword" spellcheck="false">            *   `session_id`: A consistent identifier (e.g., "blog_pagination_session") to maintain the browser state across `arun` calls.</span>
<span class="token code keyword" spellcheck="false">            *   `js_code`: JavaScript to trigger the "Next Page" action (e.g., `document.querySelector('a.next-page-link').click();`).</span>
<span class="token code keyword" spellcheck="false">            *   `wait_for`: A CSS selector or JavaScript condition to ensure the new page content has loaded before proceeding.</span>
<span class="token code keyword" spellcheck="false">            *   `js_only=True`: For subsequent `arun` calls after the initial page load to indicate only JS interaction without full navigation.</span>
<span class="token list punctuation">*</span>   4.5. Task: Get Screenshots of a List of URLs
<span class="token code keyword" spellcheck="false">    *   4.5.1. Description: Capture screenshots for a batch of URLs.</span>
<span class="token code keyword" spellcheck="false">    *   4.5.2. Key `crawl4ai` elements:</span>
<span class="token code keyword" spellcheck="false">        *   `AsyncWebCrawler`</span>
<span class="token code keyword" spellcheck="false">        *   `arun_many()` method.</span>
<span class="token code keyword" spellcheck="false">        *   `CrawlerRunConfig`:</span>
<span class="token code keyword" spellcheck="false">            *   `screenshot=True`.</span>

<span class="token title important"><span class="token punctuation">##</span> 5. Key Input Considerations for </span><span class="token code keyword" spellcheck="false">`crawl4ai`</span> Operations (Inferred from Vibe Prompting Tips)

<span class="token list punctuation">*</span>   5.1. Clear Objective: <span class="token code keyword" spellcheck="false">`crawl4ai`</span> operations are guided by the configuration. The configuration should reflect the user's goal (e.g., Markdown generation, specific data extraction, media capture).
<span class="token list punctuation">*</span>   5.2. URL Input: The <span class="token code keyword" spellcheck="false">`arun`</span> method requires a single <span class="token code keyword" spellcheck="false">`url`</span> string. <span class="token code keyword" spellcheck="false">`arun_many`</span> requires a <span class="token code keyword" spellcheck="false">`List[str]`</span> of URLs.
<span class="token list punctuation">*</span>   5.3. Structured Data Extraction Guidance:
<span class="token code keyword" spellcheck="false">    *   For `JsonCssExtractionStrategy`, the `schema` parameter (a dictionary mapping desired field names to CSS selectors) is essential.</span>
<span class="token code keyword" spellcheck="false">    *   For `LLMExtractionStrategy`, the `instruction` parameter (natural language description of desired data) and/or a `schema` (Pydantic model or dictionary) are crucial, along with a configured `LLMConfig`.</span>
<span class="token list punctuation">*</span>   5.4. LLM Configuration: When <span class="token code keyword" spellcheck="false">`LLMExtractionStrategy`</span> is used, an <span class="token code keyword" spellcheck="false">`LLMConfig`</span> instance specifying <span class="token code keyword" spellcheck="false">`provider`</span> and <span class="token code keyword" spellcheck="false">`api_token`</span> (if applicable) must be provided.
<span class="token list punctuation">*</span>   5.5. Dynamic Page Handling: For pages requiring interaction, <span class="token code keyword" spellcheck="false">`CrawlerRunConfig`</span> parameters like <span class="token code keyword" spellcheck="false">`js_code`</span>, <span class="token code keyword" spellcheck="false">`wait_for`</span>, <span class="token code keyword" spellcheck="false">`session_id`</span>, and <span class="token code keyword" spellcheck="false">`js_only`</span> are used.

<span class="token title important"><span class="token punctuation">##</span> 6. Expected Output Data from </span><span class="token code keyword" spellcheck="false">`crawl4ai`</span> Operations (Accessing <span class="token code keyword" spellcheck="false">`CrawlResult`</span>)

<span class="token list punctuation">*</span>   6.1. Generated Python Code: When using an AI assistant with <span class="token code keyword" spellcheck="false">`crawl4ai`</span> context, the AI is expected to generate Python code that utilizes <span class="token code keyword" spellcheck="false">`crawl4ai`</span> classes and methods.
<span class="token list punctuation">*</span>   6.2. <span class="token code keyword" spellcheck="false">`CrawlResult`</span> Object: The primary output of <span class="token code keyword" spellcheck="false">`arun()`</span> and <span class="token code keyword" spellcheck="false">`arun_many()`</span> calls.
<span class="token code keyword" spellcheck="false">    *   `result.success (bool)`: Indicates if the individual crawl operation was successful.</span>
<span class="token code keyword" spellcheck="false">    *   `result.markdown.raw_markdown (str)` / `result.markdown.fit_markdown (str)`: Contains the generated Markdown content.</span>
<span class="token code keyword" spellcheck="false">    *   `result.extracted_content (Optional[str])`: Contains the JSON string of structured data if an extraction strategy was successful.</span>
<span class="token code keyword" spellcheck="false">    *   `result.links (Links)`: Provides access to lists of internal and external links.</span>
<span class="token code keyword" spellcheck="false">    *   `result.media (Media)`: Provides access to lists of images, videos, audio files, and tables.</span>
<span class="token code keyword" spellcheck="false">    *   `result.screenshot (Optional[str])`: Base64 encoded screenshot data.</span>
<span class="token code keyword" spellcheck="false">    *   `result.pdf (Optional[bytes])`: Raw PDF data.</span>
<span class="token code keyword" spellcheck="false">    *   `result.error_message (Optional[str])`: Error details if `success` is `False`.</span>
<span class="token list punctuation">*</span>   6.3. Files on Disk: Operations like screenshot or PDF generation, or custom code within an AI-generated script, might save files to the local disk (e.g., PNGs, PDFs, JSON files). The paths depend on the configuration or the custom code.

</code></pre>
</div>
</body>

</html>
